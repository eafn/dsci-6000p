{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from chinese_calendar import is_holiday, is_workday, is_in_lieu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_h = pd.read_csv('./hourly_dataset.csv') #每小时间隔流量数据集，含20个小区（01-20），多个表格间对于小区的编码一致\n",
    "sub       = pd.read_csv('./sample_submission.csv') #提交样例\n",
    "test      = pd.read_csv('./test_public.csv') #测试集（小时单位），须提交20个小区、4个不连续周的供水量。也即672（小时数） x 20（小区数）的矩阵\n",
    "weather   = pd.read_csv('./weather.csv') #深圳市天气数据，测试集部分假定未知"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_transfer(df):\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    df = df.sort_values(by=['time'])\n",
    "    return df\n",
    "\n",
    "\n",
    "# def linear_interpolation(train, col):\n",
    "#     if np.isnan(train.loc[0, col]):\n",
    "#         train.loc[0, col] = train.loc[:, col].mean()\n",
    "\n",
    "#     if np.isnan(train.loc[len(train)-1, col]):\n",
    "#         train.loc[len(train)-1, col] = train.loc[:, col].mean()\n",
    "\n",
    "#     cur_train = train[col].copy()\n",
    "#     cur_train[cur_train.notnull()]=0\n",
    "#     cur_train[cur_train.isnull()]=1\n",
    "\n",
    "#     begin_index = cur_train.diff()[cur_train.diff()==1].index.values.tolist()\n",
    "#     end_index = cur_train.diff()[cur_train.diff()==-1].index.values.tolist()\n",
    "\n",
    "#     for i in range(len(begin_index)):\n",
    "#         q1 = train[col].loc[begin_index[i]-1] / (end_index[i] - begin_index[i] + 1)\n",
    "#         q2 = train[col].loc[end_index[i]] / (end_index[i] - begin_index[i] + 1)\n",
    "\n",
    "#         fill_null = [ q1*(end_index[i]-i) + q2*(i-begin_index[i]+1) for i in range(begin_index[i], end_index[i])]\n",
    "#         train[col].loc[begin_index[i]:end_index[i]-1] = fill_null\n",
    "        \n",
    "#     return train[col]\n",
    "\n",
    "\n",
    "\n",
    "def handle_outlier(dataset):\n",
    "    \n",
    "    for i in range(20):\n",
    "        col = dataset.loc[:, f'flow_{i+1}']\n",
    "        if np.isnan(col[0]):\n",
    "            col[0] = col.mean()\n",
    "        if np.isnan(col[len(col)-1]):\n",
    "            col[len(col)-1] = col.mean()\n",
    "\n",
    "        dataset.loc[:, f'flow_{i+1}'] = col.interpolate()\n",
    "\n",
    "        \n",
    "    \n",
    "    return dataset\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def process_time_features(orign_feas, flow):\n",
    "    new_feas = pd.DataFrame(orign_feas.loc[:,'time'])\n",
    "\n",
    "    # 小时\n",
    "    new_feas['hour'] = orign_feas['time'].apply(lambda x: x.hour)\n",
    "    \n",
    "    # 日\n",
    "    new_feas['day'] = orign_feas['time'].apply(lambda x: x.day)\n",
    "\n",
    "    # 月\n",
    "    new_feas['month'] = orign_feas['time'].apply(lambda x: x.month)\n",
    "    \n",
    "    # 星期\n",
    "    new_feas['day_of_week'] = orign_feas['time'].apply(lambda x: x.dayofweek)\n",
    "\n",
    "    # 期间段\n",
    "    period_of_day_dict = {\n",
    "        23: 0, 0: 0, 1: 0,\n",
    "        2: 1, 3: 1, 4: 1,\n",
    "        5: 2, 6: 2, 7: 2,\n",
    "        8: 3, 9: 3, 10: 3, 11: 3,\n",
    "        12: 4, 13: 4, 14: 4,\n",
    "        15: 5, 16: 5,\n",
    "        17: 6, 18: 6,19: 6,\n",
    "        20: 7, 21: 7, 22: 7,\n",
    "    }\n",
    "    new_feas['period_of_day'] = new_feas['hour'].map(period_of_day_dict)\n",
    "\n",
    "    # 是否营业时间\n",
    "    new_feas['work_hours'] = orign_feas['time'].apply(lambda x: 0 if x.hour >= 8 and x.hour <= 21 else 1)\n",
    "\n",
    "    # 假期\n",
    "    new_feas['holiday'] = orign_feas['time'].apply(is_holiday).astype('int')\n",
    "    \n",
    "    # 不调休\n",
    "    new_feas['lieu'] = orign_feas['time'].apply(is_in_lieu).astype('int')\n",
    "\n",
    "    # 是否月初\n",
    "    new_feas['month_start'] = orign_feas['time'].apply(lambda x: x.is_month_start).astype('int')\n",
    "\n",
    "    # 是否月末\n",
    "    new_feas['month_end'] = orign_feas['time'].apply(lambda x: x.is_month_end).astype('int')\n",
    "\n",
    "    # 季节\n",
    "    new_feas['season'] = orign_feas['time'].apply(lambda x: x.quarter)\n",
    "\n",
    "    new_feas = new_feas.drop(['time'],axis=1)\n",
    "    \n",
    "    return new_feas\n",
    "\n",
    "    \n",
    "'''\n",
    "origin_feas: features of each community, the size is n*2, including 'time', 'flow_i'\n",
    "flow: index of community \n",
    "'''\n",
    "def process_data_features(orign_feas, flow):\n",
    "    new_features = pd.DataFrame()\n",
    "\n",
    "    # 差值\n",
    "    new_features[f'flow{flow}_diff_1'] = orign_feas[flow].diff()\n",
    "    new_features[f\"flow{flow}_diff_24\"] = orign_feas[flow].diff(24)\n",
    "    new_features[f\"flow{flow}_diff_168\"] = orign_feas[flow].diff(24*7)\n",
    "\n",
    "    # 前面的值\n",
    "    new_features[f\"flow{flow}_shift_1\"] = orign_feas[flow].shift(1)\n",
    "    new_features[f\"flow{flow}_shift_24\"] = orign_feas[flow].shift(24)\n",
    "    new_features[f\"flow{flow}_shift_168\"] = orign_feas[flow].shift(168)\n",
    "\n",
    "\n",
    "    return new_features.interpolate().fillna(method='bfill')\n",
    "\n",
    "\n",
    "\n",
    "# 特征工程\n",
    "def make_features(data):\n",
    "    data = data.drop(['train or test'],axis=1)\n",
    "    community_list = []\n",
    "\n",
    "    \n",
    "    for flow in tqdm(range(20)):\n",
    "        # 添加初始特征\n",
    "        features_list = []  \n",
    "        features_list.append(pd.DataFrame(data.loc[:,[f'flow_{flow+1}']]))\n",
    "        \n",
    "        cls_feature = pd.DataFrame(np.zeros((data.shape[0],5)), columns=[f'cls_{i}' for i in range(5)])\n",
    "        cls_list = [f'cls_{i}' for i in range(5) if (int(flow / (2**i)) % 2 == 1)]\n",
    "        cls_feature.loc[:, cls_list] = 1\n",
    "        features_list.append(cls_feature)\n",
    "\n",
    "        # 未处理特征 n*2: time | flow_i\n",
    "        orign_features = pd.DataFrame(data.loc[:,['time',f'flow_{flow+1}']])\n",
    "    \n",
    "        # 添加时间特征\n",
    "        features_list.append(process_time_features(orign_features, f'flow_{flow+1}'))\n",
    "\n",
    "        # 添加数据特征\n",
    "        features_list.append(process_data_features(orign_features, f'flow_{flow+1}'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # n, c\n",
    "        new_features = np.concatenate(features_list, axis=-1)\n",
    "        \n",
    "        community_list.append(new_features)\n",
    "\n",
    "    # n*d*c\n",
    "    new_data = np.stack(community_list,axis=0).transpose(1,0,2)\n",
    "\n",
    "    return new_data\n",
    "\n",
    "\n",
    "def generate_dataset(data, seq_len, pre_len, split_ratio=0.8):\n",
    "    train_x, train_y, val_x, val_y, test_x = [], [], [], [], np.expand_dims(data[-pre_len:],axis=[0])\n",
    "    split_size = int(len(data)*split_ratio)\n",
    "    train_data = data[:split_size]\n",
    "    val_data   = data[split_size:]\n",
    "    for i in range(0, len(train_data)-seq_len-pre_len, seq_len):    \n",
    "        train_x.append(train_data[i:i+seq_len])\n",
    "        train_y.append(train_data[i+seq_len:i+seq_len+pre_len])\n",
    "    for i in range(0, len(val_data)-seq_len-pre_len, seq_len):\n",
    "        val_x.append(val_data[i:i+seq_len])\n",
    "        val_y.append(val_data[i+seq_len:i+seq_len+pre_len])\n",
    "    train_x, train_y, val_x, val_y = np.array(train_x), np.array(train_y), np.array(val_x), np.array(val_y)\n",
    "    return train_x, train_y, val_x, val_y, test_x\n",
    "\n",
    "\n",
    "\n",
    "def lightgbm_train(train_x, train_y, val_x, val_y, test_x):\n",
    "    fea_nums = train_x.shape[-1]\n",
    "    scores = []\n",
    "    predictions = []\n",
    "    for flow in tqdm(range(20)):\n",
    "        train_data_x = pd.DataFrame(train_x[:, :, flow, :].reshape(-1, fea_nums))\n",
    "        train_data_y = pd.DataFrame(train_y[:, :, flow, :].reshape(-1, fea_nums)).iloc[:,0]\n",
    "        val_data_x   = pd.DataFrame(val_x[:, :, flow, :].reshape(-1, fea_nums))\n",
    "        val_data_y   = pd.DataFrame(val_y[:, :, flow, :].reshape(-1, fea_nums)).iloc[:,0]\n",
    "        test_data_x  = pd.DataFrame(test_x[:, :, flow, :].reshape(-1, fea_nums))\n",
    "\n",
    "        train_part = lgb.Dataset(train_data_x, train_data_y)\n",
    "        val_part = lgb.Dataset(val_data_x, val_data_y)\n",
    "        ESR = 100\n",
    "        NBR = 3000\n",
    "        VBE = 100\n",
    "        lgb_params_best = {'objective': 'regression',\n",
    "                           'metric': ['mse'],\n",
    "                           'bagging_seed': 2022,\n",
    "                           'verbose': -1}\n",
    "        lgb_model = lgb.train(lgb_params_best, train_part, num_boost_round=NBR,\n",
    "                              valid_sets=[train_part, val_part],\n",
    "                              valid_names=['train', 'valid'],\n",
    "                              early_stopping_rounds=ESR, verbose_eval=None)\n",
    "        score = mean_squared_error(train_data_y, lgb_model.predict(train_data_x))\n",
    "        scores.append(round(score, 3))\n",
    "        prediction_test = lgb_model.predict(test_data_x)\n",
    "        predictions.append(prediction_test)\n",
    "    return predictions, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_h = time_transfer(dataset_h)\n",
    "test = time_transfer(test)\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    dataset_h[f'flow_{i+1}'][dataset_h[f'flow_{i+1}']<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_timestamp_start = test.groupby('train or test')['time'].first().reset_index()\n",
    "test_timestamp_start = test_timestamp_start['time'].values\n",
    "test_timestamp_end = test.groupby('train or test')['time'].last().reset_index()\n",
    "test_timestamp_end = test_timestamp_end['time'].values\n",
    "test_timestamp = np.concatenate((test_timestamp_start, test_timestamp_end), axis=0)\n",
    "test_timestamp.sort()\n",
    "\n",
    "\n",
    "# dataset part1\n",
    "dataset_train_p1 = dataset_h[dataset_h['time']<test_timestamp[0]].reset_index(drop=True)\n",
    "dataset_test_p1  = dataset_h[(dataset_h['time']>=test_timestamp[0]) & (dataset_h['time']<=test_timestamp[1])].reset_index(drop=True)\n",
    "\n",
    "# dataset part2\n",
    "dataset_train_p2 = dataset_h[(dataset_h['time']>test_timestamp[1])  & (dataset_h['time']<test_timestamp[2])].reset_index(drop=True)\n",
    "dataset_test_p2  = dataset_h[(dataset_h['time']>=test_timestamp[2]) & (dataset_h['time']<=test_timestamp[3])].reset_index(drop=True)\n",
    "\n",
    "#dataset part3\n",
    "dataset_train_p3 = dataset_h[(dataset_h['time']>test_timestamp[3])  & (dataset_h['time']<test_timestamp[4])].reset_index(drop=True)\n",
    "dataset_test_p3  = dataset_h[(dataset_h['time']>=test_timestamp[4]) & (dataset_h['time']<=test_timestamp[5])].reset_index(drop=True)\n",
    "\n",
    "#dataset part4\n",
    "dataset_train_p4 = dataset_h[(dataset_h['time']>test_timestamp[5])  & (dataset_h['time']<test_timestamp[6])].reset_index(drop=True)\n",
    "dataset_test_p4  = dataset_h[(dataset_h['time']>=test_timestamp[6]) & (dataset_h['time']<=test_timestamp[7])].reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.30it/s]\n",
      "100%|██████████| 20/20 [00:05<00:00,  3.76it/s]\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.02it/s]\n",
      "100%|██████████| 20/20 [00:07<00:00,  2.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# 处理Nan\n",
    "dataset_train_p1 = handle_outlier(dataset_train_p1)\n",
    "dataset_train_p2 = handle_outlier(dataset_train_p2)\n",
    "dataset_train_p3 = handle_outlier(dataset_train_p3)\n",
    "dataset_train_p4 = handle_outlier(dataset_train_p4)\n",
    "\n",
    "# 构建特征\n",
    "features_p1 = make_features(dataset_train_p1)\n",
    "features_p12 = make_features(pd.concat([dataset_train_p1,dataset_train_p2]))\n",
    "features_p123 = make_features(pd.concat([dataset_train_p1,dataset_train_p2,dataset_train_p3]))\n",
    "features_p1234 = make_features(pd.concat([dataset_train_p1,dataset_train_p2,dataset_train_p3,dataset_train_p4]))\n",
    "\n",
    "# 构造x和y数据\n",
    "train1_x, train1_y, val1_x, val1_y, test1_x = generate_dataset(features_p1, 24*7, 24*7)\n",
    "train2_x, train2_y, val2_x, val2_y, test2_x = generate_dataset(features_p12, 24*7, 24*7)\n",
    "train3_x, train3_y, val3_x, val3_y, test3_x = generate_dataset(features_p123, 24*7, 24*7)\n",
    "train4_x, train4_y, val4_x, val4_y, test4_x = generate_dataset(features_p1234, 24*7, 24*7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:19<00:00,  3.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57.645, 2.913, 22.93, 16.473, 0.899, 34.097, 27.597, 4.222, 0.542, 63.15, 136.175, 56.731, 3.967, 13.55, 9.126, 6.27, 16.555, 283.669, 104.409, 0.165]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:34<00:00,  4.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[68.237, 3.587, 1.525, 16.018, 0.816, 45.751, 56.486, 5.146, 0.635, 199.565, 49.517, 262.349, 8.087, 10.928, 3.887, 39.161, 97.224, 668.629, 53.175, 0.23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:23<00:00,  4.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19800.425, 18.089, 10770.737, 4522.065, 268.021, 12564.524, 784.216, 4.99, 0.687, 48.065, 117.451, 472.986, 36.838, 27.254, 16.054, 106.593, 308.899, 142.585, 167.425, 0.353]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:06<00:00,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12116.327, 19.183, 8857.866, 3518.821, 178.772, 12042.715, 486.535, 4.523, 0.948, 102.517, 88.512, 1256.098, 24.82, 30.296, 13.652, 72.783, 247.39, 231.173, 175.121, 0.473]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions1, scores1 = lightgbm_train(train1_x, train1_y, val1_x, val1_y, test1_x)\n",
    "print(scores1)\n",
    "predictions2, scores2 = lightgbm_train(train2_x, train2_y, val2_x, val2_y, test2_x)\n",
    "print(scores2)\n",
    "predictions3, scores3 = lightgbm_train(train3_x, train3_y, val3_x, val3_y, test3_x)\n",
    "print(scores3)\n",
    "predictions4, scores4 = lightgbm_train(train4_x, train4_y, val4_x, val4_y, test4_x)\n",
    "print(scores4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>flow_1</th>\n",
       "      <th>flow_2</th>\n",
       "      <th>flow_3</th>\n",
       "      <th>flow_4</th>\n",
       "      <th>flow_5</th>\n",
       "      <th>flow_6</th>\n",
       "      <th>flow_7</th>\n",
       "      <th>flow_8</th>\n",
       "      <th>flow_9</th>\n",
       "      <th>...</th>\n",
       "      <th>flow_11</th>\n",
       "      <th>flow_12</th>\n",
       "      <th>flow_13</th>\n",
       "      <th>flow_14</th>\n",
       "      <th>flow_15</th>\n",
       "      <th>flow_16</th>\n",
       "      <th>flow_17</th>\n",
       "      <th>flow_18</th>\n",
       "      <th>flow_19</th>\n",
       "      <th>flow_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-01 01:00:00</td>\n",
       "      <td>22.347972</td>\n",
       "      <td>9.345182</td>\n",
       "      <td>41.495976</td>\n",
       "      <td>24.962675</td>\n",
       "      <td>2.394873</td>\n",
       "      <td>36.747058</td>\n",
       "      <td>7.432008</td>\n",
       "      <td>1.311686</td>\n",
       "      <td>2.253646</td>\n",
       "      <td>...</td>\n",
       "      <td>5.787250</td>\n",
       "      <td>6.719144</td>\n",
       "      <td>2.270575</td>\n",
       "      <td>2.146477</td>\n",
       "      <td>1.962336</td>\n",
       "      <td>2.209960</td>\n",
       "      <td>5.002943</td>\n",
       "      <td>6.827984</td>\n",
       "      <td>4.072628</td>\n",
       "      <td>0.973326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-01 02:00:00</td>\n",
       "      <td>20.673789</td>\n",
       "      <td>5.078858</td>\n",
       "      <td>34.469438</td>\n",
       "      <td>16.379968</td>\n",
       "      <td>2.060486</td>\n",
       "      <td>25.662330</td>\n",
       "      <td>5.107360</td>\n",
       "      <td>0.992564</td>\n",
       "      <td>1.409028</td>\n",
       "      <td>...</td>\n",
       "      <td>4.954613</td>\n",
       "      <td>8.904029</td>\n",
       "      <td>0.536159</td>\n",
       "      <td>1.662967</td>\n",
       "      <td>1.460739</td>\n",
       "      <td>1.542819</td>\n",
       "      <td>3.351999</td>\n",
       "      <td>6.582776</td>\n",
       "      <td>3.455065</td>\n",
       "      <td>0.269975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-01 03:00:00</td>\n",
       "      <td>16.078742</td>\n",
       "      <td>4.045867</td>\n",
       "      <td>31.334437</td>\n",
       "      <td>14.464350</td>\n",
       "      <td>1.919481</td>\n",
       "      <td>24.703622</td>\n",
       "      <td>4.977683</td>\n",
       "      <td>0.818561</td>\n",
       "      <td>1.276453</td>\n",
       "      <td>...</td>\n",
       "      <td>4.881807</td>\n",
       "      <td>4.953903</td>\n",
       "      <td>0.437687</td>\n",
       "      <td>0.999963</td>\n",
       "      <td>1.624395</td>\n",
       "      <td>0.937625</td>\n",
       "      <td>2.051743</td>\n",
       "      <td>6.582776</td>\n",
       "      <td>4.130308</td>\n",
       "      <td>0.194478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-01 04:00:00</td>\n",
       "      <td>15.545554</td>\n",
       "      <td>3.711596</td>\n",
       "      <td>29.438549</td>\n",
       "      <td>13.972459</td>\n",
       "      <td>1.838947</td>\n",
       "      <td>22.609336</td>\n",
       "      <td>4.977683</td>\n",
       "      <td>0.656603</td>\n",
       "      <td>1.276453</td>\n",
       "      <td>...</td>\n",
       "      <td>4.881807</td>\n",
       "      <td>2.484847</td>\n",
       "      <td>0.353427</td>\n",
       "      <td>0.999963</td>\n",
       "      <td>1.377533</td>\n",
       "      <td>0.796425</td>\n",
       "      <td>1.808805</td>\n",
       "      <td>6.582776</td>\n",
       "      <td>3.616526</td>\n",
       "      <td>0.283475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-01 05:00:00</td>\n",
       "      <td>17.901963</td>\n",
       "      <td>4.052951</td>\n",
       "      <td>31.206697</td>\n",
       "      <td>14.792931</td>\n",
       "      <td>1.989797</td>\n",
       "      <td>30.019421</td>\n",
       "      <td>4.977683</td>\n",
       "      <td>0.736510</td>\n",
       "      <td>1.276453</td>\n",
       "      <td>...</td>\n",
       "      <td>4.881807</td>\n",
       "      <td>1.692545</td>\n",
       "      <td>0.279017</td>\n",
       "      <td>1.110825</td>\n",
       "      <td>1.443406</td>\n",
       "      <td>1.075036</td>\n",
       "      <td>2.123604</td>\n",
       "      <td>5.224016</td>\n",
       "      <td>3.616526</td>\n",
       "      <td>0.400317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>2022-08-27 20:00:00</td>\n",
       "      <td>69.287450</td>\n",
       "      <td>30.567747</td>\n",
       "      <td>84.067327</td>\n",
       "      <td>55.272395</td>\n",
       "      <td>9.122787</td>\n",
       "      <td>107.037257</td>\n",
       "      <td>22.268458</td>\n",
       "      <td>3.690791</td>\n",
       "      <td>11.160293</td>\n",
       "      <td>...</td>\n",
       "      <td>8.355970</td>\n",
       "      <td>11.509519</td>\n",
       "      <td>4.380829</td>\n",
       "      <td>4.524568</td>\n",
       "      <td>2.983620</td>\n",
       "      <td>8.287397</td>\n",
       "      <td>14.298699</td>\n",
       "      <td>15.009979</td>\n",
       "      <td>6.471816</td>\n",
       "      <td>4.005231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>2022-08-27 21:00:00</td>\n",
       "      <td>87.435577</td>\n",
       "      <td>42.100651</td>\n",
       "      <td>85.331624</td>\n",
       "      <td>58.856208</td>\n",
       "      <td>11.692947</td>\n",
       "      <td>117.032824</td>\n",
       "      <td>29.699284</td>\n",
       "      <td>4.824637</td>\n",
       "      <td>15.980606</td>\n",
       "      <td>...</td>\n",
       "      <td>9.200533</td>\n",
       "      <td>11.509519</td>\n",
       "      <td>4.870484</td>\n",
       "      <td>5.426695</td>\n",
       "      <td>3.597281</td>\n",
       "      <td>9.540919</td>\n",
       "      <td>15.202963</td>\n",
       "      <td>15.009979</td>\n",
       "      <td>6.471816</td>\n",
       "      <td>4.859656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>2022-08-27 22:00:00</td>\n",
       "      <td>85.444374</td>\n",
       "      <td>43.605518</td>\n",
       "      <td>85.331624</td>\n",
       "      <td>58.856208</td>\n",
       "      <td>12.120713</td>\n",
       "      <td>117.032824</td>\n",
       "      <td>29.632268</td>\n",
       "      <td>5.275649</td>\n",
       "      <td>16.728399</td>\n",
       "      <td>...</td>\n",
       "      <td>10.530876</td>\n",
       "      <td>11.509519</td>\n",
       "      <td>5.867034</td>\n",
       "      <td>5.426695</td>\n",
       "      <td>3.675592</td>\n",
       "      <td>9.959813</td>\n",
       "      <td>15.485014</td>\n",
       "      <td>15.009979</td>\n",
       "      <td>6.471816</td>\n",
       "      <td>5.177498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>2022-08-27 23:00:00</td>\n",
       "      <td>61.582276</td>\n",
       "      <td>31.189753</td>\n",
       "      <td>84.067327</td>\n",
       "      <td>62.337139</td>\n",
       "      <td>7.676372</td>\n",
       "      <td>101.858407</td>\n",
       "      <td>25.818598</td>\n",
       "      <td>3.649272</td>\n",
       "      <td>11.233480</td>\n",
       "      <td>...</td>\n",
       "      <td>8.673423</td>\n",
       "      <td>11.509519</td>\n",
       "      <td>5.867034</td>\n",
       "      <td>5.081845</td>\n",
       "      <td>3.030228</td>\n",
       "      <td>9.365193</td>\n",
       "      <td>12.823904</td>\n",
       "      <td>17.654162</td>\n",
       "      <td>6.471816</td>\n",
       "      <td>4.668908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>2022-08-28 00:00:00</td>\n",
       "      <td>37.674837</td>\n",
       "      <td>20.038529</td>\n",
       "      <td>81.829942</td>\n",
       "      <td>52.534033</td>\n",
       "      <td>5.071019</td>\n",
       "      <td>86.322134</td>\n",
       "      <td>29.836554</td>\n",
       "      <td>2.313125</td>\n",
       "      <td>6.350621</td>\n",
       "      <td>...</td>\n",
       "      <td>10.462589</td>\n",
       "      <td>11.116995</td>\n",
       "      <td>8.262693</td>\n",
       "      <td>3.872530</td>\n",
       "      <td>2.569707</td>\n",
       "      <td>13.702135</td>\n",
       "      <td>10.273715</td>\n",
       "      <td>20.390526</td>\n",
       "      <td>6.471816</td>\n",
       "      <td>2.437146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>672 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    time     flow_1     flow_2     flow_3     flow_4  \\\n",
       "0    2022-05-01 01:00:00  22.347972   9.345182  41.495976  24.962675   \n",
       "1    2022-05-01 02:00:00  20.673789   5.078858  34.469438  16.379968   \n",
       "2    2022-05-01 03:00:00  16.078742   4.045867  31.334437  14.464350   \n",
       "3    2022-05-01 04:00:00  15.545554   3.711596  29.438549  13.972459   \n",
       "4    2022-05-01 05:00:00  17.901963   4.052951  31.206697  14.792931   \n",
       "..                   ...        ...        ...        ...        ...   \n",
       "667  2022-08-27 20:00:00  69.287450  30.567747  84.067327  55.272395   \n",
       "668  2022-08-27 21:00:00  87.435577  42.100651  85.331624  58.856208   \n",
       "669  2022-08-27 22:00:00  85.444374  43.605518  85.331624  58.856208   \n",
       "670  2022-08-27 23:00:00  61.582276  31.189753  84.067327  62.337139   \n",
       "671  2022-08-28 00:00:00  37.674837  20.038529  81.829942  52.534033   \n",
       "\n",
       "        flow_5      flow_6     flow_7    flow_8     flow_9  ...    flow_11  \\\n",
       "0     2.394873   36.747058   7.432008  1.311686   2.253646  ...   5.787250   \n",
       "1     2.060486   25.662330   5.107360  0.992564   1.409028  ...   4.954613   \n",
       "2     1.919481   24.703622   4.977683  0.818561   1.276453  ...   4.881807   \n",
       "3     1.838947   22.609336   4.977683  0.656603   1.276453  ...   4.881807   \n",
       "4     1.989797   30.019421   4.977683  0.736510   1.276453  ...   4.881807   \n",
       "..         ...         ...        ...       ...        ...  ...        ...   \n",
       "667   9.122787  107.037257  22.268458  3.690791  11.160293  ...   8.355970   \n",
       "668  11.692947  117.032824  29.699284  4.824637  15.980606  ...   9.200533   \n",
       "669  12.120713  117.032824  29.632268  5.275649  16.728399  ...  10.530876   \n",
       "670   7.676372  101.858407  25.818598  3.649272  11.233480  ...   8.673423   \n",
       "671   5.071019   86.322134  29.836554  2.313125   6.350621  ...  10.462589   \n",
       "\n",
       "       flow_12   flow_13   flow_14   flow_15    flow_16    flow_17    flow_18  \\\n",
       "0     6.719144  2.270575  2.146477  1.962336   2.209960   5.002943   6.827984   \n",
       "1     8.904029  0.536159  1.662967  1.460739   1.542819   3.351999   6.582776   \n",
       "2     4.953903  0.437687  0.999963  1.624395   0.937625   2.051743   6.582776   \n",
       "3     2.484847  0.353427  0.999963  1.377533   0.796425   1.808805   6.582776   \n",
       "4     1.692545  0.279017  1.110825  1.443406   1.075036   2.123604   5.224016   \n",
       "..         ...       ...       ...       ...        ...        ...        ...   \n",
       "667  11.509519  4.380829  4.524568  2.983620   8.287397  14.298699  15.009979   \n",
       "668  11.509519  4.870484  5.426695  3.597281   9.540919  15.202963  15.009979   \n",
       "669  11.509519  5.867034  5.426695  3.675592   9.959813  15.485014  15.009979   \n",
       "670  11.509519  5.867034  5.081845  3.030228   9.365193  12.823904  17.654162   \n",
       "671  11.116995  8.262693  3.872530  2.569707  13.702135  10.273715  20.390526   \n",
       "\n",
       "      flow_19   flow_20  \n",
       "0    4.072628  0.973326  \n",
       "1    3.455065  0.269975  \n",
       "2    4.130308  0.194478  \n",
       "3    3.616526  0.283475  \n",
       "4    3.616526  0.400317  \n",
       "..        ...       ...  \n",
       "667  6.471816  4.005231  \n",
       "668  6.471816  4.859656  \n",
       "669  6.471816  5.177498  \n",
       "670  6.471816  4.668908  \n",
       "671  6.471816  2.437146  \n",
       "\n",
       "[672 rows x 21 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = np.concatenate((np.vstack(predictions1).transpose(1,0),\n",
    "                         np.vstack(predictions2).transpose(1,0),\n",
    "                         np.vstack(predictions3).transpose(1,0),\n",
    "                         np.vstack(predictions4).transpose(1,0)))\n",
    "result[result<0]=0\n",
    "result = pd.concat([sub['time'],pd.DataFrame(result)],axis=1)\n",
    "result.columns = sub.columns\n",
    "result.to_csv('./lgb_baseline.csv',index=False,encoding='utf-8')\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c05f55e50b4a9b62fba3579247947ea58cd2eac0f20b2e6982b321c7b5fb553f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
